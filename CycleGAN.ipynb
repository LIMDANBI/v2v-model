{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176e9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch # batch_size channel width height\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646438c2",
   "metadata": {},
   "source": [
    "## GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6ed789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f745b",
   "metadata": {},
   "source": [
    "## SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3ce59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b95c2",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c56fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, A_dir, B_dir, img_size=256):\n",
    "        self.A_dir = photo_dir\n",
    "        self.B_dir = gogh_dir\n",
    "        self.A_imgs = [filename for filename in os.listdir(A_dir) if os.path.splitext(filename)[-1] in ('.jpg', '.png') ]\n",
    "        self.B_imgs = [filename for filename in os.listdir(B_dir) if os.path.splitext(filename)[-1] in ('.jpg', '.png') ]\n",
    "        self.transform = [ torchvision.transforms.Resize(int(img_size*1.15), Image.BICUBIC), # 이미지 크기를 조금 키우기\n",
    "                           torchvision.transforms.RandomCrop(img_size), \n",
    "                           torchvision.transforms.RandomHorizontalFlip(),\n",
    "                           torchvision.transforms.ToTensor(),  #  [0 - 255] --> [0 - 1.0]\n",
    "                           torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
    "        self.transform = torchvision.transforms.Compose(self.transform)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        A_img = self.transform(Image.open(os.path.join(self.A_dir, \n",
    "                                                       self.A_imgs[index % len(self.A_imgs)])).convert('RGB'))\n",
    "        B_img = self.transform(Image.open(os.path.join(self.B_dir, \n",
    "                                                       self.B_imgs[random.randint(0, len(self.B_imgs) - 1)])).convert('RGB')) # 랜덤 샘플링\n",
    "        return A_img, B_img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(len(self.A_dir), len(self.B_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3816f209",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8398e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_dir = '../data/scenary/'\n",
    "gogh_dir = '../data/gogh/'\n",
    "train_dataset = ImageDataset(photo_dir, gogh_dir)\n",
    "valid_dataset = ImageDataset(photo_dir, gogh_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(valid_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6bab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7ff0ca2be240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f26e545",
   "metadata": {},
   "source": [
    "## Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ce5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        # 채널(channel) 크기는 그대로 유지\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(in_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985ce4a",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25797eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_residual_blocks):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "\n",
    "        channels = input_shape[0] # 입력 이미지의 채널 수: 3\n",
    "\n",
    "        # 초기 Convolution layer\n",
    "        out_channels = 64\n",
    "        model = [nn.ReflectionPad2d(channels)]\n",
    "        model.append(nn.Conv2d(channels, out_channels, kernel_size=7))\n",
    "        model.append(nn.InstanceNorm2d(out_channels))\n",
    "        model.append(nn.ReLU(inplace=True))\n",
    "        in_channels = out_channels\n",
    "\n",
    "        # Downsampling\n",
    "        for _ in range(2):\n",
    "            out_channels *= 2\n",
    "            model.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)) # 너비와 높이가 2배씩 감소\n",
    "            model.append(nn.InstanceNorm2d(out_channels))\n",
    "            model.append(nn.ReLU(inplace=True))\n",
    "            in_channels = out_channels\n",
    "        # 출력: [256 X (4배 감소한 높이) X (4배 감소한 너비)]\n",
    "\n",
    "        # 인코더와 디코더의 중간에서 Residual Blocks 사용 (차원 유지)\n",
    "        for _ in range(num_residual_blocks):\n",
    "            model.append(ResidualBlock(out_channels))\n",
    "\n",
    "        # Upsampling\n",
    "        for _ in range(2):\n",
    "            out_channels //= 2\n",
    "            model.append(nn.Upsample(scale_factor=2)) # 너비와 높이가 2배씩 증가\n",
    "            model.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)) # 너비와 높이는 그대로\n",
    "            model.append(nn.InstanceNorm2d(out_channels))\n",
    "            model.append(nn.ReLU(inplace=True))\n",
    "            in_channels = out_channels\n",
    "        # 출력: [256 X (4배 증가한 높이) X (4배 증가한 너비)]\n",
    "\n",
    "        # 출력 Convolution Block layer\n",
    "        model.append(nn.ReflectionPad2d(channels))\n",
    "        model.append(nn.Conv2d(out_channels, channels, kernel_size=7))\n",
    "        model.append(nn.Tanh())\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d878c",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae9822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        channels, height, width = input_shape \n",
    "\n",
    "        # Convolution Block\n",
    "        def discriminator_block(in_channels, out_channels, normalize=True):\n",
    "            layers = [nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)] # 너비와 높이가 2배씩 감소\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 64, normalize=False), # 출력: [64 X 128 X 128]\n",
    "            *discriminator_block(64, 128), # 출력: [128 X 64 X 64]\n",
    "            *discriminator_block(128, 256), # 출력: [256 X 32 X 32]\n",
    "            *discriminator_block(256, 512), # 출력: [512 X 16 X 16]\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 3, kernel_size=4, padding=1) # 출력: [3 X 16 X 16]\n",
    "        )\n",
    "        # 최종 출력: [3 X (16배 감소한 높이) X (16배 감소한 너비)]\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7571421",
   "metadata": {},
   "source": [
    "## ReplayBuffer\n",
    "\n",
    "Replay Buffer GAN 트레이닝을 진행하며 똑같은 샘플별로 성능을 살펴보면 트레이닝을 돌릴때마다 성능이 천차만별이다. 이 불안정성을 해결하기 위해 주기적으로 Generator가 만들어 놓은 사진을 다시 discriminator에게 보여줌, 이 부분은 Discriminator에게만 적용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c1e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    # 새로운 이미지를 삽입하고, 이전에 삽입되었던 이미지를 반환하는 함수\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            # 아직 버퍼가 가득 차지 않았다면, 현재 삽입된 데이터를 반환\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            # 버퍼가 가득 찼다면, 이전에 삽입되었던 이미지를 랜덤하게 반환\n",
    "            else:\n",
    "                if random.uniform(0, 1) > 0.5: # 확률은 50%\n",
    "                    i = random.randint(0, self.max_size - 1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element # 버퍼에 들어 있는 이미지 교체\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17672412",
   "metadata": {},
   "source": [
    "## Learning Rate 조정\n",
    "시간이 지남에 따라 학습률(learning rate) 조정(감소)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ff081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLR:\n",
    "    def __init__(self, n_epochs, decay_start_epoch):\n",
    "        self.n_epochs = n_epochs # 전체 epoch\n",
    "        self.decay_start_epoch = decay_start_epoch # 학습률 감소가 시작되는 epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a614eb",
   "metadata": {},
   "source": [
    "## 가중치 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deeb98a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if hasattr(m, \"bias\") and m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af3ecb",
   "metadata": {},
   "source": [
    "## Generator와 Discriminator 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b291dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "    (12): Conv2d(512, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "G_AB = GeneratorResNet(input_shape=(3, 256, 256), num_residual_blocks=9)\n",
    "G_BA = GeneratorResNet(input_shape=(3, 256, 256), num_residual_blocks=9)\n",
    "D_A = Discriminator(input_shape=(3, 256, 256))\n",
    "D_B = Discriminator(input_shape=(3, 256, 256))\n",
    "\n",
    "G_AB.cuda()\n",
    "G_BA.cuda()\n",
    "D_A.cuda()\n",
    "D_B.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "320a2bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
       "    (12): Conv2d(512, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치(weights) 초기화\n",
    "G_AB.apply(weights_init_normal)\n",
    "G_BA.apply(weights_init_normal)\n",
    "D_A.apply(weights_init_normal)\n",
    "D_B.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6967441",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b4a308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L1Loss()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "criterion_GAN.cuda()\n",
    "criterion_cycle.cuda()\n",
    "criterion_identity.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f1b3e",
   "metadata": {},
   "source": [
    "## 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c20b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200 # 학습의 횟수(epoch) 설정\n",
    "decay_epoch = 100\n",
    "lr = 0.0002 # 학습률(learning rate) 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb388b7",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6a12706",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D_A  = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c2066",
   "metadata": {},
   "source": [
    "## 학습률(learning rate) 업데이트 스케줄러 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0cf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3029e8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5bde189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbibibi/.conda/envs/dev/lib/python3.6/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([4, 1, 16, 16])) that is different to the input size (torch.Size([4, 3, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done 0/4] [Elapsed time: 2.51s]\n",
      "[Epoch 0/200] [D loss: 1.434710] [G identity loss: 0.457904, adv loss: 1.5701693296432495, cycle loss: 0.5568963885307312] [Elapsed time: 7.54s]\n",
      "Model saved!\n",
      "[Epoch 1/200] [D loss: 0.920286] [G identity loss: 0.431080, adv loss: 0.8508347272872925, cycle loss: 0.49207034707069397] [Elapsed time: 13.27s]\n",
      "Model saved!\n",
      "[Epoch 2/200] [D loss: 0.810025] [G identity loss: 0.385519, adv loss: 0.7768833637237549, cycle loss: 0.41738617420196533] [Elapsed time: 19.33s]\n",
      "Model saved!\n",
      "[Epoch 3/200] [D loss: 0.626251] [G identity loss: 0.382108, adv loss: 0.5760961174964905, cycle loss: 0.4016782343387604] [Elapsed time: 25.14s]\n",
      "Model saved!\n",
      "[Epoch 4/200] [D loss: 0.522142] [G identity loss: 0.295782, adv loss: 0.4969215989112854, cycle loss: 0.32707515358924866] [Elapsed time: 31.30s]\n",
      "Model saved!\n",
      "[Epoch 5/200] [D loss: 0.431621] [G identity loss: 0.287795, adv loss: 0.3994126319885254, cycle loss: 0.3128988742828369] [Elapsed time: 37.17s]\n",
      "Model saved!\n",
      "[Epoch 6/200] [D loss: 0.391679] [G identity loss: 0.257979, adv loss: 0.385948121547699, cycle loss: 0.28140076994895935] [Elapsed time: 43.68s]\n",
      "Model saved!\n",
      "[Epoch 7/200] [D loss: 0.392323] [G identity loss: 0.264294, adv loss: 0.3742593824863434, cycle loss: 0.2890733480453491] [Elapsed time: 49.59s]\n",
      "Model saved!\n",
      "[Epoch 8/200] [D loss: 0.338077] [G identity loss: 0.240349, adv loss: 0.36520349979400635, cycle loss: 0.26771867275238037] [Elapsed time: 55.59s]\n",
      "Model saved!\n",
      "[Epoch 9/200] [D loss: 0.338230] [G identity loss: 0.288821, adv loss: 0.3535020053386688, cycle loss: 0.300538033246994] [Elapsed time: 61.30s]\n",
      "Model saved!\n",
      "[Epoch 10/200] [D loss: 0.337520] [G identity loss: 0.272305, adv loss: 0.3545341491699219, cycle loss: 0.2964138388633728] [Elapsed time: 67.41s]\n",
      "Model saved!\n",
      "[Epoch 11/200] [D loss: 0.334818] [G identity loss: 0.250401, adv loss: 0.3500998616218567, cycle loss: 0.27229994535446167] [Elapsed time: 73.31s]\n",
      "Model saved!\n",
      "[Done 2/4] [Elapsed time: 79.02s]\n",
      "[Epoch 12/200] [D loss: 0.306298] [G identity loss: 0.233461, adv loss: 0.3142911195755005, cycle loss: 0.2540639638900757] [Elapsed time: 80.40s]\n",
      "Model saved!\n",
      "[Epoch 13/200] [D loss: 0.310691] [G identity loss: 0.256539, adv loss: 0.3453565239906311, cycle loss: 0.2764328122138977] [Elapsed time: 86.34s]\n",
      "Model saved!\n",
      "[Epoch 14/200] [D loss: 0.290977] [G identity loss: 0.249224, adv loss: 0.29060542583465576, cycle loss: 0.265114426612854] [Elapsed time: 92.15s]\n",
      "Model saved!\n",
      "[Epoch 15/200] [D loss: 0.282478] [G identity loss: 0.280136, adv loss: 0.3348309397697449, cycle loss: 0.30757126212120056] [Elapsed time: 97.85s]\n",
      "Model saved!\n",
      "[Epoch 16/200] [D loss: 0.274067] [G identity loss: 0.253528, adv loss: 0.34787821769714355, cycle loss: 0.28798338770866394] [Elapsed time: 103.67s]\n",
      "Model saved!\n",
      "[Epoch 17/200] [D loss: 0.292937] [G identity loss: 0.234987, adv loss: 0.2835428714752197, cycle loss: 0.2599215805530548] [Elapsed time: 109.92s]\n",
      "Model saved!\n",
      "[Epoch 18/200] [D loss: 0.294584] [G identity loss: 0.254790, adv loss: 0.35223719477653503, cycle loss: 0.2790988087654114] [Elapsed time: 115.99s]\n",
      "Model saved!\n",
      "[Epoch 19/200] [D loss: 0.285926] [G identity loss: 0.250443, adv loss: 0.3296777009963989, cycle loss: 0.27388980984687805] [Elapsed time: 121.97s]\n",
      "Model saved!\n",
      "[Epoch 20/200] [D loss: 0.281820] [G identity loss: 0.280533, adv loss: 0.3047747015953064, cycle loss: 0.313770055770874] [Elapsed time: 127.81s]\n",
      "Model saved!\n",
      "[Epoch 21/200] [D loss: 0.275314] [G identity loss: 0.274196, adv loss: 0.3549465835094452, cycle loss: 0.3100172281265259] [Elapsed time: 133.56s]\n",
      "Model saved!\n",
      "[Epoch 22/200] [D loss: 0.285814] [G identity loss: 0.260420, adv loss: 0.3463832437992096, cycle loss: 0.2898361086845398] [Elapsed time: 139.42s]\n",
      "Model saved!\n",
      "[Epoch 23/200] [D loss: 0.294789] [G identity loss: 0.211657, adv loss: 0.3367176949977875, cycle loss: 0.24171900749206543] [Elapsed time: 145.04s]\n",
      "Model saved!\n",
      "[Epoch 24/200] [D loss: 0.312027] [G identity loss: 0.225455, adv loss: 0.39630836248397827, cycle loss: 0.24020931124687195] [Elapsed time: 151.20s]\n",
      "Model saved!\n",
      "[Done 0/4] [Elapsed time: 154.41s]\n",
      "[Epoch 25/200] [D loss: 0.288838] [G identity loss: 0.259109, adv loss: 0.3229357600212097, cycle loss: 0.295529842376709] [Elapsed time: 158.39s]\n",
      "Model saved!\n",
      "[Epoch 26/200] [D loss: 0.294877] [G identity loss: 0.239738, adv loss: 0.39232027530670166, cycle loss: 0.2731143832206726] [Elapsed time: 164.27s]\n",
      "Model saved!\n",
      "[Epoch 27/200] [D loss: 0.257133] [G identity loss: 0.265238, adv loss: 0.3402402102947235, cycle loss: 0.3064141571521759] [Elapsed time: 170.18s]\n",
      "Model saved!\n",
      "[Epoch 28/200] [D loss: 0.262191] [G identity loss: 0.212056, adv loss: 0.36383000016212463, cycle loss: 0.2210855633020401] [Elapsed time: 175.93s]\n",
      "Model saved!\n",
      "[Epoch 29/200] [D loss: 0.318710] [G identity loss: 0.279799, adv loss: 0.34056851267814636, cycle loss: 0.3416162133216858] [Elapsed time: 181.59s]\n",
      "Model saved!\n",
      "[Epoch 30/200] [D loss: 0.252193] [G identity loss: 0.234749, adv loss: 0.34420523047447205, cycle loss: 0.24634429812431335] [Elapsed time: 187.25s]\n",
      "Model saved!\n",
      "[Epoch 31/200] [D loss: 0.273980] [G identity loss: 0.225170, adv loss: 0.3124891519546509, cycle loss: 0.24337011575698853] [Elapsed time: 193.25s]\n",
      "Model saved!\n",
      "[Epoch 32/200] [D loss: 0.262510] [G identity loss: 0.258697, adv loss: 0.32015731930732727, cycle loss: 0.29155483841896057] [Elapsed time: 199.52s]\n",
      "Model saved!\n",
      "[Epoch 33/200] [D loss: 0.223696] [G identity loss: 0.228302, adv loss: 0.3951297998428345, cycle loss: 0.25616583228111267] [Elapsed time: 205.64s]\n",
      "Model saved!\n",
      "[Epoch 34/200] [D loss: 0.243102] [G identity loss: 0.291320, adv loss: 0.35469263792037964, cycle loss: 0.36664879322052] [Elapsed time: 211.44s]\n",
      "Model saved!\n",
      "[Epoch 35/200] [D loss: 0.251164] [G identity loss: 0.207479, adv loss: 0.3316833972930908, cycle loss: 0.24313722550868988] [Elapsed time: 217.66s]\n",
      "Model saved!\n",
      "[Epoch 36/200] [D loss: 0.258446] [G identity loss: 0.250406, adv loss: 0.30788666009902954, cycle loss: 0.26828527450561523] [Elapsed time: 223.54s]\n",
      "Model saved!\n",
      "[Done 2/4] [Elapsed time: 229.41s]\n",
      "[Epoch 37/200] [D loss: 0.247699] [G identity loss: 0.223310, adv loss: 0.32036292552948, cycle loss: 0.25731998682022095] [Elapsed time: 230.63s]\n",
      "Model saved!\n",
      "[Epoch 38/200] [D loss: 0.261204] [G identity loss: 0.239585, adv loss: 0.3404054641723633, cycle loss: 0.26447150111198425] [Elapsed time: 236.56s]\n",
      "Model saved!\n",
      "[Epoch 39/200] [D loss: 0.271936] [G identity loss: 0.216192, adv loss: 0.3672902286052704, cycle loss: 0.24500083923339844] [Elapsed time: 242.23s]\n",
      "Model saved!\n",
      "[Epoch 40/200] [D loss: 0.264936] [G identity loss: 0.208265, adv loss: 0.32248958945274353, cycle loss: 0.2410096973180771] [Elapsed time: 248.37s]\n",
      "Model saved!\n",
      "[Epoch 41/200] [D loss: 0.235190] [G identity loss: 0.233398, adv loss: 0.38529694080352783, cycle loss: 0.2565091848373413] [Elapsed time: 254.49s]\n",
      "Model saved!\n",
      "[Epoch 42/200] [D loss: 0.275777] [G identity loss: 0.188154, adv loss: 0.30974024534225464, cycle loss: 0.20758463442325592] [Elapsed time: 260.67s]\n",
      "Model saved!\n",
      "[Epoch 43/200] [D loss: 0.287482] [G identity loss: 0.245278, adv loss: 0.3024638891220093, cycle loss: 0.2846109867095947] [Elapsed time: 266.43s]\n",
      "Model saved!\n",
      "[Epoch 44/200] [D loss: 0.235211] [G identity loss: 0.184671, adv loss: 0.37330833077430725, cycle loss: 0.2150186449289322] [Elapsed time: 272.24s]\n",
      "Model saved!\n",
      "[Epoch 45/200] [D loss: 0.227790] [G identity loss: 0.222320, adv loss: 0.3492209017276764, cycle loss: 0.25440263748168945] [Elapsed time: 277.92s]\n",
      "Model saved!\n",
      "[Epoch 46/200] [D loss: 0.268924] [G identity loss: 0.188273, adv loss: 0.27758336067199707, cycle loss: 0.2120128870010376] [Elapsed time: 284.34s]\n",
      "Model saved!\n",
      "[Epoch 47/200] [D loss: 0.249256] [G identity loss: 0.232203, adv loss: 0.3335302770137787, cycle loss: 0.2540677785873413] [Elapsed time: 290.27s]\n",
      "Model saved!\n",
      "[Epoch 48/200] [D loss: 0.226161] [G identity loss: 0.195128, adv loss: 0.3944433033466339, cycle loss: 0.2209101915359497] [Elapsed time: 296.03s]\n",
      "Model saved!\n",
      "[Epoch 49/200] [D loss: 0.223438] [G identity loss: 0.200836, adv loss: 0.36661094427108765, cycle loss: 0.21873779594898224] [Elapsed time: 302.28s]\n",
      "Model saved!\n",
      "[Done 0/4] [Elapsed time: 305.22s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50/200] [D loss: 0.238599] [G identity loss: 0.223189, adv loss: 0.3298575282096863, cycle loss: 0.24992907047271729] [Elapsed time: 308.98s]\n",
      "Model saved!\n",
      "[Epoch 51/200] [D loss: 0.244643] [G identity loss: 0.220026, adv loss: 0.36597740650177, cycle loss: 0.2584075331687927] [Elapsed time: 314.91s]\n",
      "Model saved!\n",
      "[Epoch 52/200] [D loss: 0.242432] [G identity loss: 0.198208, adv loss: 0.37587112188339233, cycle loss: 0.22058835625648499] [Elapsed time: 320.70s]\n",
      "Model saved!\n",
      "[Epoch 53/200] [D loss: 0.222375] [G identity loss: 0.197530, adv loss: 0.2907327711582184, cycle loss: 0.21548958122730255] [Elapsed time: 326.70s]\n",
      "Model saved!\n",
      "[Epoch 54/200] [D loss: 0.249572] [G identity loss: 0.201292, adv loss: 0.35156676173210144, cycle loss: 0.22842523455619812] [Elapsed time: 332.66s]\n",
      "Model saved!\n",
      "[Epoch 55/200] [D loss: 0.270036] [G identity loss: 0.209923, adv loss: 0.3852035403251648, cycle loss: 0.23129390180110931] [Elapsed time: 338.80s]\n",
      "Model saved!\n",
      "[Epoch 56/200] [D loss: 0.239899] [G identity loss: 0.218301, adv loss: 0.33629679679870605, cycle loss: 0.25785404443740845] [Elapsed time: 345.05s]\n",
      "Model saved!\n",
      "[Epoch 57/200] [D loss: 0.251953] [G identity loss: 0.184322, adv loss: 0.37107351422309875, cycle loss: 0.21291112899780273] [Elapsed time: 350.88s]\n",
      "Model saved!\n",
      "[Epoch 58/200] [D loss: 0.291370] [G identity loss: 0.208865, adv loss: 0.3371692895889282, cycle loss: 0.2503012418746948] [Elapsed time: 356.59s]\n",
      "Model saved!\n",
      "[Epoch 59/200] [D loss: 0.266684] [G identity loss: 0.197543, adv loss: 0.4062456488609314, cycle loss: 0.2193724662065506] [Elapsed time: 362.34s]\n",
      "Model saved!\n",
      "[Epoch 60/200] [D loss: 0.274823] [G identity loss: 0.280769, adv loss: 0.3603176474571228, cycle loss: 0.3437042832374573] [Elapsed time: 368.21s]\n",
      "Model saved!\n",
      "[Epoch 61/200] [D loss: 0.297950] [G identity loss: 0.228467, adv loss: 0.3431657552719116, cycle loss: 0.26235073804855347] [Elapsed time: 374.23s]\n",
      "Model saved!\n",
      "[Done 2/4] [Elapsed time: 379.49s]\n",
      "[Epoch 62/200] [D loss: 0.222753] [G identity loss: 0.234339, adv loss: 0.35981982946395874, cycle loss: 0.2960164546966553] [Elapsed time: 381.57s]\n",
      "Model saved!\n",
      "[Epoch 63/200] [D loss: 0.203567] [G identity loss: 0.216662, adv loss: 0.4207490086555481, cycle loss: 0.2254870980978012] [Elapsed time: 387.54s]\n",
      "Model saved!\n",
      "[Epoch 64/200] [D loss: 0.248356] [G identity loss: 0.200629, adv loss: 0.34886395931243896, cycle loss: 0.23137633502483368] [Elapsed time: 393.69s]\n",
      "Model saved!\n",
      "[Epoch 65/200] [D loss: 0.215821] [G identity loss: 0.191192, adv loss: 0.32040202617645264, cycle loss: 0.2148372232913971] [Elapsed time: 399.29s]\n",
      "Model saved!\n",
      "[Epoch 66/200] [D loss: 0.252895] [G identity loss: 0.232641, adv loss: 0.3538953363895416, cycle loss: 0.25066253542900085] [Elapsed time: 405.33s]\n",
      "Model saved!\n",
      "[Epoch 67/200] [D loss: 0.219599] [G identity loss: 0.194732, adv loss: 0.36575445532798767, cycle loss: 0.22716978192329407] [Elapsed time: 410.83s]\n",
      "Model saved!\n",
      "[Epoch 68/200] [D loss: 0.250217] [G identity loss: 0.234043, adv loss: 0.38505929708480835, cycle loss: 0.26993197202682495] [Elapsed time: 416.61s]\n",
      "Model saved!\n",
      "[Epoch 69/200] [D loss: 0.296581] [G identity loss: 0.198403, adv loss: 0.38875794410705566, cycle loss: 0.21779300272464752] [Elapsed time: 422.37s]\n",
      "Model saved!\n",
      "[Epoch 70/200] [D loss: 0.270374] [G identity loss: 0.154586, adv loss: 0.3054242432117462, cycle loss: 0.17516681551933289] [Elapsed time: 428.18s]\n",
      "Model saved!\n",
      "[Epoch 71/200] [D loss: 0.241710] [G identity loss: 0.215777, adv loss: 0.31468749046325684, cycle loss: 0.2571721374988556] [Elapsed time: 434.41s]\n",
      "Model saved!\n",
      "[Epoch 72/200] [D loss: 0.264593] [G identity loss: 0.204962, adv loss: 0.3044632375240326, cycle loss: 0.22467327117919922] [Elapsed time: 440.49s]\n",
      "Model saved!\n",
      "[Epoch 73/200] [D loss: 0.252720] [G identity loss: 0.236891, adv loss: 0.3802238702774048, cycle loss: 0.2572585642337799] [Elapsed time: 446.25s]\n",
      "Model saved!\n",
      "[Epoch 74/200] [D loss: 0.230179] [G identity loss: 0.172056, adv loss: 0.35875996947288513, cycle loss: 0.1938932240009308] [Elapsed time: 452.51s]\n",
      "Model saved!\n",
      "[Done 0/4] [Elapsed time: 454.98s]\n",
      "[Epoch 75/200] [D loss: 0.251237] [G identity loss: 0.186059, adv loss: 0.3428884446620941, cycle loss: 0.21293513476848602] [Elapsed time: 459.21s]\n",
      "Model saved!\n",
      "[Epoch 76/200] [D loss: 0.287053] [G identity loss: 0.219147, adv loss: 0.36355435848236084, cycle loss: 0.23316983878612518] [Elapsed time: 464.95s]\n",
      "Model saved!\n",
      "[Epoch 77/200] [D loss: 0.214257] [G identity loss: 0.200549, adv loss: 0.40501081943511963, cycle loss: 0.20636382699012756] [Elapsed time: 471.17s]\n",
      "Model saved!\n",
      "[Epoch 78/200] [D loss: 0.200248] [G identity loss: 0.168636, adv loss: 0.3718980550765991, cycle loss: 0.1952933818101883] [Elapsed time: 477.10s]\n",
      "Model saved!\n",
      "[Epoch 79/200] [D loss: 0.233466] [G identity loss: 0.186740, adv loss: 0.4124225378036499, cycle loss: 0.21288400888442993] [Elapsed time: 483.11s]\n",
      "Model saved!\n",
      "[Epoch 80/200] [D loss: 0.236635] [G identity loss: 0.205886, adv loss: 0.3835034966468811, cycle loss: 0.23537570238113403] [Elapsed time: 489.00s]\n",
      "Model saved!\n",
      "[Epoch 81/200] [D loss: 0.241348] [G identity loss: 0.196315, adv loss: 0.43266481161117554, cycle loss: 0.21422111988067627] [Elapsed time: 494.76s]\n",
      "Model saved!\n",
      "[Epoch 82/200] [D loss: 0.309765] [G identity loss: 0.187715, adv loss: 0.3542032837867737, cycle loss: 0.21408799290657043] [Elapsed time: 500.47s]\n",
      "Model saved!\n",
      "[Epoch 83/200] [D loss: 0.271902] [G identity loss: 0.182442, adv loss: 0.3923788070678711, cycle loss: 0.21020865440368652] [Elapsed time: 506.69s]\n",
      "Model saved!\n",
      "[Epoch 84/200] [D loss: 0.216374] [G identity loss: 0.184826, adv loss: 0.40250787138938904, cycle loss: 0.19498251378536224] [Elapsed time: 512.46s]\n",
      "Model saved!\n",
      "[Epoch 85/200] [D loss: 0.200822] [G identity loss: 0.189460, adv loss: 0.36458101868629456, cycle loss: 0.20414534211158752] [Elapsed time: 518.32s]\n",
      "Model saved!\n",
      "[Epoch 86/200] [D loss: 0.267182] [G identity loss: 0.154637, adv loss: 0.5218362808227539, cycle loss: 0.17609381675720215] [Elapsed time: 524.07s]\n",
      "Model saved!\n",
      "[Done 2/4] [Elapsed time: 529.83s]\n",
      "[Epoch 87/200] [D loss: 0.246032] [G identity loss: 0.190031, adv loss: 0.3363553285598755, cycle loss: 0.21223461627960205] [Elapsed time: 531.08s]\n",
      "Model saved!\n",
      "[Epoch 88/200] [D loss: 0.255106] [G identity loss: 0.169266, adv loss: 0.302196741104126, cycle loss: 0.1945255994796753] [Elapsed time: 536.96s]\n",
      "Model saved!\n",
      "[Epoch 89/200] [D loss: 0.223092] [G identity loss: 0.143284, adv loss: 0.3925572633743286, cycle loss: 0.16372092068195343] [Elapsed time: 542.61s]\n",
      "Model saved!\n",
      "[Epoch 90/200] [D loss: 0.214112] [G identity loss: 0.217939, adv loss: 0.36500096321105957, cycle loss: 0.2435128092765808] [Elapsed time: 548.34s]\n",
      "Model saved!\n",
      "[Epoch 91/200] [D loss: 0.228265] [G identity loss: 0.207740, adv loss: 0.35633915662765503, cycle loss: 0.22527757287025452] [Elapsed time: 554.10s]\n",
      "Model saved!\n",
      "[Epoch 92/200] [D loss: 0.240736] [G identity loss: 0.194088, adv loss: 0.4014992117881775, cycle loss: 0.20537982881069183] [Elapsed time: 560.32s]\n",
      "Model saved!\n",
      "[Epoch 93/200] [D loss: 0.232514] [G identity loss: 0.158055, adv loss: 0.329725444316864, cycle loss: 0.17846527695655823] [Elapsed time: 566.13s]\n",
      "Model saved!\n",
      "[Epoch 94/200] [D loss: 0.239828] [G identity loss: 0.199594, adv loss: 0.371743381023407, cycle loss: 0.24368295073509216] [Elapsed time: 572.46s]\n",
      "Model saved!\n",
      "[Epoch 95/200] [D loss: 0.224081] [G identity loss: 0.197549, adv loss: 0.36590778827667236, cycle loss: 0.2073982059955597] [Elapsed time: 578.21s]\n",
      "Model saved!\n",
      "[Epoch 96/200] [D loss: 0.204399] [G identity loss: 0.193367, adv loss: 0.4315173625946045, cycle loss: 0.21788930892944336] [Elapsed time: 584.24s]\n",
      "Model saved!\n",
      "[Epoch 97/200] [D loss: 0.204122] [G identity loss: 0.177901, adv loss: 0.4073672592639923, cycle loss: 0.21498672664165497] [Elapsed time: 589.74s]\n",
      "Model saved!\n",
      "[Epoch 98/200] [D loss: 0.257191] [G identity loss: 0.163833, adv loss: 0.34641414880752563, cycle loss: 0.1979784071445465] [Elapsed time: 595.55s]\n",
      "Model saved!\n",
      "[Epoch 99/200] [D loss: 0.303247] [G identity loss: 0.198593, adv loss: 0.5263988971710205, cycle loss: 0.22684001922607422] [Elapsed time: 601.36s]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done 0/4] [Elapsed time: 604.15s]\n",
      "[Epoch 100/200] [D loss: 0.215894] [G identity loss: 0.179788, adv loss: 0.4304780960083008, cycle loss: 0.20141692459583282] [Elapsed time: 608.55s]\n",
      "Model saved!\n",
      "[Epoch 101/200] [D loss: 0.192917] [G identity loss: 0.163414, adv loss: 0.34288012981414795, cycle loss: 0.17777732014656067] [Elapsed time: 614.13s]\n",
      "Model saved!\n",
      "[Epoch 102/200] [D loss: 0.209128] [G identity loss: 0.176305, adv loss: 0.43422731757164, cycle loss: 0.19656610488891602] [Elapsed time: 620.32s]\n",
      "Model saved!\n",
      "[Epoch 103/200] [D loss: 0.231178] [G identity loss: 0.175307, adv loss: 0.42305007576942444, cycle loss: 0.20929986238479614] [Elapsed time: 626.50s]\n",
      "Model saved!\n",
      "[Epoch 104/200] [D loss: 0.226062] [G identity loss: 0.175953, adv loss: 0.4105236232280731, cycle loss: 0.19173309206962585] [Elapsed time: 632.43s]\n",
      "Model saved!\n",
      "[Epoch 105/200] [D loss: 0.238193] [G identity loss: 0.175539, adv loss: 0.38359808921813965, cycle loss: 0.1990567296743393] [Elapsed time: 638.54s]\n",
      "Model saved!\n",
      "[Epoch 106/200] [D loss: 0.227830] [G identity loss: 0.179933, adv loss: 0.38770776987075806, cycle loss: 0.1912921965122223] [Elapsed time: 644.40s]\n",
      "Model saved!\n",
      "[Epoch 107/200] [D loss: 0.240936] [G identity loss: 0.149707, adv loss: 0.3484507203102112, cycle loss: 0.15636859834194183] [Elapsed time: 650.51s]\n",
      "Model saved!\n",
      "[Epoch 108/200] [D loss: 0.187104] [G identity loss: 0.170572, adv loss: 0.3640112280845642, cycle loss: 0.1805994212627411] [Elapsed time: 656.06s]\n",
      "Model saved!\n",
      "[Epoch 109/200] [D loss: 0.226910] [G identity loss: 0.156302, adv loss: 0.37095093727111816, cycle loss: 0.17076852917671204] [Elapsed time: 662.10s]\n",
      "Model saved!\n",
      "[Epoch 110/200] [D loss: 0.234273] [G identity loss: 0.214550, adv loss: 0.33957889676094055, cycle loss: 0.2485148310661316] [Elapsed time: 667.77s]\n",
      "Model saved!\n",
      "[Epoch 111/200] [D loss: 0.230156] [G identity loss: 0.184037, adv loss: 0.3770698308944702, cycle loss: 0.19045740365982056] [Elapsed time: 673.69s]\n",
      "Model saved!\n",
      "[Done 2/4] [Elapsed time: 679.23s]\n",
      "[Epoch 112/200] [D loss: 0.200462] [G identity loss: 0.151421, adv loss: 0.40440306067466736, cycle loss: 0.16755208373069763] [Elapsed time: 680.53s]\n",
      "Model saved!\n",
      "[Epoch 113/200] [D loss: 0.263030] [G identity loss: 0.153790, adv loss: 0.4733271598815918, cycle loss: 0.16925346851348877] [Elapsed time: 686.40s]\n",
      "Model saved!\n",
      "[Epoch 114/200] [D loss: 0.249479] [G identity loss: 0.149184, adv loss: 0.5116667151451111, cycle loss: 0.1635497361421585] [Elapsed time: 692.06s]\n",
      "Model saved!\n",
      "[Epoch 115/200] [D loss: 0.196157] [G identity loss: 0.149982, adv loss: 0.3028591275215149, cycle loss: 0.16580796241760254] [Elapsed time: 698.23s]\n",
      "Model saved!\n",
      "[Epoch 116/200] [D loss: 0.262027] [G identity loss: 0.188981, adv loss: 0.2858496904373169, cycle loss: 0.21562126278877258] [Elapsed time: 704.34s]\n",
      "Model saved!\n",
      "[Epoch 117/200] [D loss: 0.218393] [G identity loss: 0.154942, adv loss: 0.2960720360279083, cycle loss: 0.15732616186141968] [Elapsed time: 709.63s]\n",
      "Model saved!\n",
      "[Epoch 118/200] [D loss: 0.245264] [G identity loss: 0.155004, adv loss: 0.4331192672252655, cycle loss: 0.17519930005073547] [Elapsed time: 715.13s]\n",
      "Model saved!\n",
      "[Epoch 119/200] [D loss: 0.270432] [G identity loss: 0.219827, adv loss: 0.2312440723180771, cycle loss: 0.2291470617055893] [Elapsed time: 721.13s]\n",
      "Model saved!\n",
      "[Epoch 120/200] [D loss: 0.187231] [G identity loss: 0.146294, adv loss: 0.5041788816452026, cycle loss: 0.18424127995967865] [Elapsed time: 726.84s]\n",
      "Model saved!\n",
      "[Epoch 121/200] [D loss: 0.238821] [G identity loss: 0.173393, adv loss: 0.3975793719291687, cycle loss: 0.19152653217315674] [Elapsed time: 732.74s]\n",
      "Model saved!\n",
      "[Epoch 122/200] [D loss: 0.171157] [G identity loss: 0.184505, adv loss: 0.3742139935493469, cycle loss: 0.2166721373796463] [Elapsed time: 738.89s]\n",
      "Model saved!\n",
      "[Epoch 123/200] [D loss: 0.188850] [G identity loss: 0.180823, adv loss: 0.39058101177215576, cycle loss: 0.1944855898618698] [Elapsed time: 744.95s]\n",
      "Model saved!\n",
      "[Epoch 124/200] [D loss: 0.187558] [G identity loss: 0.154669, adv loss: 0.4203929305076599, cycle loss: 0.16027092933654785] [Elapsed time: 750.73s]\n",
      "Model saved!\n",
      "[Done 0/4] [Elapsed time: 753.24s]\n",
      "[Epoch 125/200] [D loss: 0.137393] [G identity loss: 0.135973, adv loss: 0.4485568106174469, cycle loss: 0.160864919424057] [Elapsed time: 757.98s]\n",
      "Model saved!\n",
      "[Epoch 126/200] [D loss: 0.134306] [G identity loss: 0.139806, adv loss: 0.49235787987709045, cycle loss: 0.15631349384784698] [Elapsed time: 763.77s]\n",
      "Model saved!\n",
      "[Epoch 127/200] [D loss: 0.180587] [G identity loss: 0.155328, adv loss: 0.35610806941986084, cycle loss: 0.17698808014392853] [Elapsed time: 769.93s]\n",
      "Model saved!\n",
      "[Epoch 128/200] [D loss: 0.241671] [G identity loss: 0.158832, adv loss: 0.4400561451911926, cycle loss: 0.17255955934524536] [Elapsed time: 776.01s]\n",
      "Model saved!\n",
      "[Epoch 129/200] [D loss: 0.180891] [G identity loss: 0.162430, adv loss: 0.4002557098865509, cycle loss: 0.17656199634075165] [Elapsed time: 782.13s]\n",
      "Model saved!\n",
      "[Epoch 130/200] [D loss: 0.203212] [G identity loss: 0.172540, adv loss: 0.46684667468070984, cycle loss: 0.1849430650472641] [Elapsed time: 788.24s]\n",
      "Model saved!\n",
      "[Epoch 131/200] [D loss: 0.196318] [G identity loss: 0.176223, adv loss: 0.3772934377193451, cycle loss: 0.17241331934928894] [Elapsed time: 794.08s]\n",
      "Model saved!\n",
      "[Epoch 132/200] [D loss: 0.198129] [G identity loss: 0.187294, adv loss: 0.38217759132385254, cycle loss: 0.19324128329753876] [Elapsed time: 800.24s]\n",
      "Model saved!\n",
      "[Epoch 133/200] [D loss: 0.203024] [G identity loss: 0.163724, adv loss: 0.4124320149421692, cycle loss: 0.18142732977867126] [Elapsed time: 806.22s]\n",
      "Model saved!\n",
      "[Epoch 134/200] [D loss: 0.168355] [G identity loss: 0.137397, adv loss: 0.6339831352233887, cycle loss: 0.16193322837352753] [Elapsed time: 812.27s]\n",
      "Model saved!\n",
      "[Epoch 135/200] [D loss: 0.228074] [G identity loss: 0.140579, adv loss: 0.5036081075668335, cycle loss: 0.16403396427631378] [Elapsed time: 818.45s]\n",
      "Model saved!\n",
      "[Epoch 136/200] [D loss: 0.166089] [G identity loss: 0.146940, adv loss: 0.3877982497215271, cycle loss: 0.16304419934749603] [Elapsed time: 824.56s]\n",
      "Model saved!\n",
      "[Done 2/4] [Elapsed time: 830.17s]\n",
      "[Epoch 137/200] [D loss: 0.192316] [G identity loss: 0.162612, adv loss: 0.40674522519111633, cycle loss: 0.17941291630268097] [Elapsed time: 831.40s]\n",
      "Model saved!\n",
      "[Epoch 138/200] [D loss: 0.221452] [G identity loss: 0.156330, adv loss: 0.46654194593429565, cycle loss: 0.16839009523391724] [Elapsed time: 837.18s]\n",
      "Model saved!\n",
      "[Epoch 139/200] [D loss: 0.183725] [G identity loss: 0.154037, adv loss: 0.4773898720741272, cycle loss: 0.1599818766117096] [Elapsed time: 843.03s]\n",
      "Model saved!\n",
      "[Epoch 140/200] [D loss: 0.195754] [G identity loss: 0.139146, adv loss: 0.5130274295806885, cycle loss: 0.15248923003673553] [Elapsed time: 848.87s]\n",
      "Model saved!\n",
      "[Epoch 141/200] [D loss: 0.233751] [G identity loss: 0.159569, adv loss: 0.4653335511684418, cycle loss: 0.1667877584695816] [Elapsed time: 854.58s]\n",
      "Model saved!\n",
      "[Epoch 142/200] [D loss: 0.167631] [G identity loss: 0.159085, adv loss: 0.38843828439712524, cycle loss: 0.17332904040813446] [Elapsed time: 860.52s]\n",
      "Model saved!\n",
      "[Epoch 143/200] [D loss: 0.197749] [G identity loss: 0.175785, adv loss: 0.37891244888305664, cycle loss: 0.18685725331306458] [Elapsed time: 866.65s]\n",
      "Model saved!\n",
      "[Epoch 144/200] [D loss: 0.226764] [G identity loss: 0.158567, adv loss: 0.47199100255966187, cycle loss: 0.1653541922569275] [Elapsed time: 871.98s]\n",
      "Model saved!\n",
      "[Epoch 145/200] [D loss: 0.199737] [G identity loss: 0.150692, adv loss: 0.358981192111969, cycle loss: 0.1601245254278183] [Elapsed time: 877.67s]\n",
      "Model saved!\n",
      "[Epoch 146/200] [D loss: 0.223253] [G identity loss: 0.151748, adv loss: 0.5300542116165161, cycle loss: 0.1585386097431183] [Elapsed time: 883.54s]\n",
      "Model saved!\n",
      "[Epoch 147/200] [D loss: 0.193126] [G identity loss: 0.159707, adv loss: 0.40691256523132324, cycle loss: 0.17452464997768402] [Elapsed time: 889.22s]\n",
      "Model saved!\n",
      "[Epoch 148/200] [D loss: 0.188468] [G identity loss: 0.192520, adv loss: 0.49853166937828064, cycle loss: 0.19460535049438477] [Elapsed time: 895.00s]\n",
      "Model saved!\n",
      "[Epoch 149/200] [D loss: 0.194909] [G identity loss: 0.148375, adv loss: 0.6267160177230835, cycle loss: 0.14720648527145386] [Elapsed time: 900.65s]\n",
      "Model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done 0/4] [Elapsed time: 903.55s]\n",
      "[Epoch 150/200] [D loss: 0.200284] [G identity loss: 0.170685, adv loss: 0.35765784978866577, cycle loss: 0.1718934327363968] [Elapsed time: 907.61s]\n",
      "Model saved!\n",
      "[Epoch 151/200] [D loss: 0.166320] [G identity loss: 0.132304, adv loss: 0.5516176223754883, cycle loss: 0.14101043343544006] [Elapsed time: 913.36s]\n",
      "Model saved!\n",
      "[Epoch 152/200] [D loss: 0.192002] [G identity loss: 0.143869, adv loss: 0.41252097487449646, cycle loss: 0.14714446663856506] [Elapsed time: 919.12s]\n",
      "Model saved!\n",
      "[Epoch 153/200] [D loss: 0.165780] [G identity loss: 0.165972, adv loss: 0.4353264272212982, cycle loss: 0.1699172556400299] [Elapsed time: 924.91s]\n",
      "Model saved!\n",
      "[Epoch 154/200] [D loss: 0.177007] [G identity loss: 0.136117, adv loss: 0.4658746123313904, cycle loss: 0.14732509851455688] [Elapsed time: 930.49s]\n",
      "Model saved!\n",
      "[Epoch 155/200] [D loss: 0.162348] [G identity loss: 0.161125, adv loss: 0.3987753093242645, cycle loss: 0.1743139922618866] [Elapsed time: 936.26s]\n",
      "Model saved!\n",
      "[Epoch 156/200] [D loss: 0.122970] [G identity loss: 0.145562, adv loss: 0.47463637590408325, cycle loss: 0.1587696373462677] [Elapsed time: 941.97s]\n",
      "Model saved!\n",
      "[Epoch 157/200] [D loss: 0.206307] [G identity loss: 0.152428, adv loss: 0.4106179475784302, cycle loss: 0.16959035396575928] [Elapsed time: 948.22s]\n",
      "Model saved!\n",
      "[Epoch 158/200] [D loss: 0.188006] [G identity loss: 0.173090, adv loss: 0.36817729473114014, cycle loss: 0.17568811774253845] [Elapsed time: 953.66s]\n",
      "Model saved!\n",
      "[Epoch 159/200] [D loss: 0.194925] [G identity loss: 0.153512, adv loss: 0.5269787907600403, cycle loss: 0.15040023624897003] [Elapsed time: 959.70s]\n",
      "Model saved!\n",
      "[Epoch 160/200] [D loss: 0.191154] [G identity loss: 0.130526, adv loss: 0.6165621280670166, cycle loss: 0.13419054448604584] [Elapsed time: 965.66s]\n",
      "Model saved!\n",
      "[Epoch 161/200] [D loss: 0.135556] [G identity loss: 0.142099, adv loss: 0.5703603029251099, cycle loss: 0.15150755643844604] [Elapsed time: 971.32s]\n",
      "Model saved!\n",
      "[Done 2/4] [Elapsed time: 976.03s]\n",
      "[Epoch 162/200] [D loss: 0.186217] [G identity loss: 0.163260, adv loss: 0.4361618459224701, cycle loss: 0.17386335134506226] [Elapsed time: 977.96s]\n",
      "Model saved!\n",
      "[Epoch 163/200] [D loss: 0.168338] [G identity loss: 0.153433, adv loss: 0.5285308361053467, cycle loss: 0.162828266620636] [Elapsed time: 983.48s]\n",
      "Model saved!\n",
      "[Epoch 164/200] [D loss: 0.169017] [G identity loss: 0.143837, adv loss: 0.3893391489982605, cycle loss: 0.15018458664417267] [Elapsed time: 989.49s]\n",
      "Model saved!\n",
      "[Epoch 165/200] [D loss: 0.173363] [G identity loss: 0.187396, adv loss: 0.39867353439331055, cycle loss: 0.18159279227256775] [Elapsed time: 995.03s]\n",
      "Model saved!\n",
      "[Epoch 166/200] [D loss: 0.211049] [G identity loss: 0.151006, adv loss: 0.3762047290802002, cycle loss: 0.15943622589111328] [Elapsed time: 1000.96s]\n",
      "Model saved!\n",
      "[Epoch 167/200] [D loss: 0.153157] [G identity loss: 0.133715, adv loss: 0.4954017102718353, cycle loss: 0.1320875883102417] [Elapsed time: 1006.77s]\n",
      "Model saved!\n",
      "[Epoch 168/200] [D loss: 0.164981] [G identity loss: 0.157736, adv loss: 0.5781926512718201, cycle loss: 0.16556820273399353] [Elapsed time: 1012.77s]\n",
      "Model saved!\n",
      "[Epoch 169/200] [D loss: 0.177334] [G identity loss: 0.136973, adv loss: 0.4254617691040039, cycle loss: 0.141484797000885] [Elapsed time: 1018.71s]\n",
      "Model saved!\n",
      "[Epoch 170/200] [D loss: 0.217613] [G identity loss: 0.171648, adv loss: 0.41466349363327026, cycle loss: 0.16498920321464539] [Elapsed time: 1024.67s]\n",
      "Model saved!\n",
      "[Epoch 171/200] [D loss: 0.182356] [G identity loss: 0.157468, adv loss: 0.4619724452495575, cycle loss: 0.16394376754760742] [Elapsed time: 1030.84s]\n",
      "Model saved!\n",
      "[Epoch 172/200] [D loss: 0.176252] [G identity loss: 0.137925, adv loss: 0.38745492696762085, cycle loss: 0.14629603922367096] [Elapsed time: 1036.44s]\n",
      "Model saved!\n",
      "[Epoch 173/200] [D loss: 0.164072] [G identity loss: 0.163541, adv loss: 0.4152817726135254, cycle loss: 0.1650789976119995] [Elapsed time: 1042.02s]\n",
      "Model saved!\n",
      "[Epoch 174/200] [D loss: 0.173595] [G identity loss: 0.153111, adv loss: 0.47042831778526306, cycle loss: 0.15766310691833496] [Elapsed time: 1047.34s]\n",
      "Model saved!\n",
      "[Done 0/4] [Elapsed time: 1049.87s]\n",
      "[Epoch 175/200] [D loss: 0.147543] [G identity loss: 0.130953, adv loss: 0.42511987686157227, cycle loss: 0.14257773756980896] [Elapsed time: 1054.45s]\n",
      "Model saved!\n",
      "[Epoch 176/200] [D loss: 0.139491] [G identity loss: 0.129798, adv loss: 0.4151316285133362, cycle loss: 0.1375550627708435] [Elapsed time: 1060.03s]\n",
      "Model saved!\n",
      "[Epoch 177/200] [D loss: 0.182604] [G identity loss: 0.150369, adv loss: 0.36185222864151, cycle loss: 0.1624799370765686] [Elapsed time: 1066.02s]\n",
      "Model saved!\n",
      "[Epoch 178/200] [D loss: 0.182045] [G identity loss: 0.177588, adv loss: 0.3784273564815521, cycle loss: 0.1680840402841568] [Elapsed time: 1071.92s]\n",
      "Model saved!\n",
      "[Epoch 179/200] [D loss: 0.144566] [G identity loss: 0.149695, adv loss: 0.4149931073188782, cycle loss: 0.1470526158809662] [Elapsed time: 1077.68s]\n",
      "Model saved!\n",
      "[Epoch 180/200] [D loss: 0.185073] [G identity loss: 0.135328, adv loss: 0.42167672514915466, cycle loss: 0.13857325911521912] [Elapsed time: 1083.57s]\n",
      "Model saved!\n",
      "[Epoch 181/200] [D loss: 0.184300] [G identity loss: 0.160783, adv loss: 0.45606347918510437, cycle loss: 0.15765272080898285] [Elapsed time: 1089.69s]\n",
      "Model saved!\n",
      "[Epoch 182/200] [D loss: 0.142895] [G identity loss: 0.161711, adv loss: 0.46214067935943604, cycle loss: 0.16547468304634094] [Elapsed time: 1096.06s]\n",
      "Model saved!\n",
      "[Epoch 183/200] [D loss: 0.212086] [G identity loss: 0.155757, adv loss: 0.3618740439414978, cycle loss: 0.15160180628299713] [Elapsed time: 1101.83s]\n",
      "Model saved!\n",
      "[Epoch 184/200] [D loss: 0.254422] [G identity loss: 0.164147, adv loss: 0.3833683133125305, cycle loss: 0.16337840259075165] [Elapsed time: 1108.07s]\n",
      "Model saved!\n",
      "[Epoch 185/200] [D loss: 0.179979] [G identity loss: 0.149903, adv loss: 0.3589354455471039, cycle loss: 0.14913272857666016] [Elapsed time: 1113.89s]\n",
      "Model saved!\n",
      "[Epoch 186/200] [D loss: 0.185174] [G identity loss: 0.144432, adv loss: 0.4462389647960663, cycle loss: 0.14499497413635254] [Elapsed time: 1119.76s]\n",
      "Model saved!\n",
      "[Done 2/4] [Elapsed time: 1124.74s]\n",
      "[Epoch 187/200] [D loss: 0.206070] [G identity loss: 0.130311, adv loss: 0.4078708291053772, cycle loss: 0.1252414882183075] [Elapsed time: 1126.71s]\n",
      "Model saved!\n",
      "[Epoch 188/200] [D loss: 0.192652] [G identity loss: 0.136727, adv loss: 0.4452712833881378, cycle loss: 0.13485883176326752] [Elapsed time: 1132.47s]\n",
      "Model saved!\n",
      "[Epoch 189/200] [D loss: 0.166153] [G identity loss: 0.151298, adv loss: 0.47985124588012695, cycle loss: 0.1481219381093979] [Elapsed time: 1138.06s]\n",
      "Model saved!\n",
      "[Epoch 190/200] [D loss: 0.170281] [G identity loss: 0.150801, adv loss: 0.45606744289398193, cycle loss: 0.14641514420509338] [Elapsed time: 1144.02s]\n",
      "Model saved!\n",
      "[Epoch 191/200] [D loss: 0.207652] [G identity loss: 0.148670, adv loss: 0.36772358417510986, cycle loss: 0.13974054157733917] [Elapsed time: 1149.55s]\n",
      "Model saved!\n",
      "[Epoch 192/200] [D loss: 0.155888] [G identity loss: 0.109691, adv loss: 0.39512866735458374, cycle loss: 0.11387698352336884] [Elapsed time: 1155.48s]\n",
      "Model saved!\n",
      "[Epoch 193/200] [D loss: 0.174521] [G identity loss: 0.140268, adv loss: 0.46711209416389465, cycle loss: 0.14202497899532318] [Elapsed time: 1161.40s]\n",
      "Model saved!\n",
      "[Epoch 194/200] [D loss: 0.190914] [G identity loss: 0.147023, adv loss: 0.40607190132141113, cycle loss: 0.14402985572814941] [Elapsed time: 1167.39s]\n",
      "Model saved!\n",
      "[Epoch 195/200] [D loss: 0.189956] [G identity loss: 0.147056, adv loss: 0.3423437178134918, cycle loss: 0.1446177363395691] [Elapsed time: 1173.45s]\n",
      "Model saved!\n",
      "[Epoch 196/200] [D loss: 0.148643] [G identity loss: 0.133361, adv loss: 0.4793614149093628, cycle loss: 0.1380467563867569] [Elapsed time: 1179.56s]\n",
      "Model saved!\n",
      "[Epoch 197/200] [D loss: 0.178654] [G identity loss: 0.143344, adv loss: 0.4554424583911896, cycle loss: 0.14334741234779358] [Elapsed time: 1185.41s]\n",
      "Model saved!\n",
      "[Epoch 198/200] [D loss: 0.207009] [G identity loss: 0.122695, adv loss: 0.3946990966796875, cycle loss: 0.11971431970596313] [Elapsed time: 1191.69s]\n",
      "Model saved!\n",
      "[Epoch 199/200] [D loss: 0.190759] [G identity loss: 0.146305, adv loss: 0.38247957825660706, cycle loss: 0.1430676281452179] [Elapsed time: 1197.31s]\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "sample_interval = 50 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "\n",
    "lambda_cycle = 10 # Cycle 손실 가중치(weight) 파라미터\n",
    "lambda_identity = 5 # Identity 손실 가중치(weight) 파라미터\n",
    "\n",
    "# 이전에 생성된 이미지 데이터를 포함하고 있는 버퍼(buffer) 객체\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # 모델의 입력(input) 데이터 불러오기\n",
    "        real_A, real_B = batch\n",
    "        real_A = real_A.cuda()\n",
    "        real_B = real_B.cuda()\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성 (너바와 높이를 16씩 나눈 크기)\n",
    "        real = torch.cuda.FloatTensor(real_A.size(0), 1, 16, 16).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(real_A.size(0), 1, 16, 16).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        G_AB.train()\n",
    "        G_BA.train()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity 손실(loss) 값 계산\n",
    "        loss_identity_A = criterion_identity(G_BA(real_A), real_A)\n",
    "        loss_identity_B = criterion_identity(G_AB(real_B), real_B)\n",
    "        loss_identity = (loss_identity_A + loss_identity_B) / 2\n",
    "\n",
    "        # GAN 손실(loss) 값 계산\n",
    "        fake_B = G_AB(real_A)\n",
    "        fake_A = G_BA(real_B)\n",
    "        loss_GAN_AB = criterion_GAN(D_B(fake_B), real)\n",
    "        loss_GAN_BA = criterion_GAN(D_A(fake_A), real)\n",
    "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
    "\n",
    "        # Cycle 손실(loss) 값 계산\n",
    "        recover_A = G_BA(fake_B)\n",
    "        recover_B = G_AB(fake_A)\n",
    "        loss_cycle_A = criterion_cycle(recover_A, real_A)\n",
    "        loss_cycle_B = criterion_cycle(recover_B, real_B)\n",
    "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
    "\n",
    "        # 최종적인 손실(loss)\n",
    "        loss_G = loss_GAN + lambda_cycle * loss_cycle + lambda_identity * loss_identity\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator) A를 학습합니다. \"\"\"\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real 손실(loss): 원본 이미지를 원본으로 판별하도록\n",
    "        loss_real = criterion_GAN(D_A(real_A), real)\n",
    "\n",
    "        # Fake 손실(loss): 가짜 이미지를 가짜로 판별하도록\n",
    "        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n",
    "        loss_fake = criterion_GAN(D_A(fake_A_.detach()), fake)\n",
    "\n",
    "        # 최종적인 손실(loss)\n",
    "        loss_D_A = (loss_real + loss_fake) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator) B를 학습합니다. \"\"\"\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real 손실(loss): 원본 이미지를 원본으로 판별하도록\n",
    "        loss_real = criterion_GAN(D_B(real_B), real)\n",
    "\n",
    "        # Fake 손실(loss): 가짜 이미지를 가짜로 판별하도록\n",
    "        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n",
    "        loss_fake = criterion_GAN(D_B(fake_B_.detach()), fake)\n",
    "\n",
    "        # 최종적인 손실(loss)\n",
    "        loss_D_B = (loss_real + loss_fake) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        loss_D = (loss_D_A + loss_D_B) / 2\n",
    "\n",
    "        done = epoch * len(train_loader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            G_AB.eval()\n",
    "            G_BA.eval()\n",
    "            imgs = next(iter(val_loader)) # 5개의 이미지를 추출해 생성\n",
    "            real_A, real_B = batch\n",
    "            real_A = real_A.cuda()\n",
    "            real_B = real_B.cuda()\n",
    "            fake_B = G_AB(real_A)\n",
    "            fake_A = G_BA(real_B)\n",
    "            \n",
    "            # X축을 따라 각각의 그리디 이미지 생성\n",
    "            real_A = make_grid(real_A, nrow=4, normalize=True)\n",
    "            real_B = make_grid(real_B, nrow=4, normalize=True)\n",
    "            fake_A = make_grid(fake_A, nrow=4, normalize=True)\n",
    "            fake_B = make_grid(fake_B, nrow=4, normalize=True)\n",
    "            \n",
    "            # 각각의 격자 이미지를 높이(height)를 기준으로 연결하기 \n",
    "            image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n",
    "            save_image(image_grid, f\"./generate_gogh/{done}.png\", normalize=False)\n",
    "            print(f\"[Done {i}/{len(train_loader)}] [Elapsed time: {time.time() - start_time:.2f}s]\")\n",
    "\n",
    "    # 학습률(learning rate)\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {loss_D.item():.6f}] [G identity loss: {loss_identity.item():.6f}, adv loss: {loss_GAN.item()}, cycle loss: {loss_cycle.item()}] [Elapsed time: {time.time() - start_time:.2f}s]\")\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 모델 파라미터 저장\n",
    "    torch.save(G_AB.state_dict(), \"G_AB_gogh.pt\")\n",
    "    torch.save(G_BA.state_dict(), \"G_BA_gogh.pt\")\n",
    "    torch.save(D_A.state_dict(), \"D_A_gogh.pt\")\n",
    "    torch.save(D_B.state_dict(), \"D_B_gogh.pt\")\n",
    "    print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f4f8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
